{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/homebrew/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset,DatasetDict, load_dataset\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 70807/70807 [00:00<00:00, 2303699.93 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 19972/19972 [00:00<00:00, 1879695.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 10087/10087 [00:00<00:00, 1604518.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review_text', 'F', 'BR', 'AU', 'FI', 'IR', 'A', 'L', 'LF', 'MN', 'O', 'PE', 'SC', 'SE', 'US', 'PO', '__index_level_0__'],\n",
       "        num_rows: 70807\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review_text', 'F', 'BR', 'AU', 'FI', 'IR', 'A', 'L', 'LF', 'MN', 'O', 'PE', 'SC', 'SE', 'US', 'PO', '__index_level_0__'],\n",
       "        num_rows: 19972\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review_text', 'F', 'BR', 'AU', 'FI', 'IR', 'A', 'L', 'LF', 'MN', 'O', 'PE', 'SC', 'SE', 'US', 'PO', '__index_level_0__'],\n",
       "        num_rows: 10087\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_directory = '../_2_data_generation-gemini-pro/Dataset/'\n",
    "files = os.listdir(dataset_directory)\n",
    "\n",
    "data_df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(f\"{dataset_directory}{file}\")\n",
    "    data_df = pd.concat([data_df, df], axis=0)\n",
    "\n",
    "bool_columns = ['F', 'BR', 'AU', 'FI', 'IR', 'A', 'L', 'LF', 'MN', 'O', 'PE', 'SC', 'SE', 'US', 'PO']\n",
    "data_df[bool_columns] = data_df[bool_columns].astype(bool)\n",
    "data_df = data_df.dropna(subset=['review_text'])\n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.22\n",
    "test_ratio = 0.10\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(data_df, test_size=test_ratio, random_state=42)\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=val_ratio, random_state=42)\n",
    "\n",
    "split_datasets = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_dataset),\n",
    "    'validation': Dataset.from_pandas(val_dataset),\n",
    "    'test': Dataset.from_pandas(test_dataset)\n",
    "})\n",
    "\n",
    "split_datasets.save_to_disk(\"./hugging-face-dataset/dataset\")\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Note that you can also easily load your local data (i.e. csv files, txt files, Parquet files, JSON, ...) as explained [here](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: review_text, Data Type: string\n",
      "Feature: F, Data Type: bool\n",
      "Feature: BR, Data Type: bool\n",
      "Feature: AU, Data Type: bool\n",
      "Feature: FI, Data Type: bool\n",
      "Feature: IR, Data Type: bool\n",
      "Feature: A, Data Type: bool\n",
      "Feature: L, Data Type: bool\n",
      "Feature: LF, Data Type: bool\n",
      "Feature: MN, Data Type: bool\n",
      "Feature: O, Data Type: bool\n",
      "Feature: PE, Data Type: bool\n",
      "Feature: SC, Data Type: bool\n",
      "Feature: SE, Data Type: bool\n",
      "Feature: US, Data Type: bool\n",
      "Feature: PO, Data Type: bool\n",
      "Feature: __index_level_0__, Data Type: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetDict.load_from_disk(\"./hugging-face-dataset/dataset/\")\n",
    "features = dataset[\"train\"].features\n",
    "for feature_name, feature_info in features.items():\n",
    "    data_type = feature_info.dtype\n",
    "    print(f\"Feature: {feature_name}, Data Type: {data_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review_text', 'F', 'BR', 'AU', 'FI', 'IR', 'A', 'L', 'LF', 'MN', 'O', 'PE', 'SC', 'SE', 'US', 'PO', '__index_level_0__'],\n",
       "        num_rows: 70807\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review_text', 'F', 'BR', 'AU', 'FI', 'IR', 'A', 'L', 'LF', 'MN', 'O', 'PE', 'SC', 'SE', 'US', 'PO', '__index_level_0__'],\n",
       "        num_rows: 19972\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review_text', 'F', 'BR', 'AU', 'FI', 'IR', 'A', 'L', 'LF', 'MN', 'O', 'PE', 'SC', 'SE', 'US', 'PO', '__index_level_0__'],\n",
       "        num_rows: 10087\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first example of the training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_text': 'Really bad UX. Old, outdated thinking. Should be redesigned asap.',\n",
       " 'F': False,\n",
       " 'BR': False,\n",
       " 'AU': False,\n",
       " 'FI': False,\n",
       " 'IR': False,\n",
       " 'A': False,\n",
       " 'L': False,\n",
       " 'LF': True,\n",
       " 'MN': False,\n",
       " 'O': False,\n",
       " 'PE': False,\n",
       " 'SC': False,\n",
       " 'SE': False,\n",
       " 'US': False,\n",
       " 'PO': False,\n",
       " '__index_level_0__': 6679}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of app reviews, labeled with one or more emotions.\n",
    "\n",
    "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F',\n",
       " 'BR',\n",
       " 'AU',\n",
       " 'FI',\n",
       " 'IR',\n",
       " 'A',\n",
       " 'L',\n",
       " 'LF',\n",
       " 'MN',\n",
       " 'O',\n",
       " 'PE',\n",
       " 'SC',\n",
       " 'SE',\n",
       " 'US',\n",
       " 'PO']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in dataset['train'].features.keys() if label not in ['__index_level_0__', 'review_text']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
    "\n",
    "What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  if examples[\"review_text\"] == None:\n",
    "    return None\n",
    "  # take a batch of texts\n",
    "  text = examples[\"review_text\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256)\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 70807/70807 [00:04<00:00, 17404.13 examples/s]\n",
      "Map: 100%|██████████| 19972/19972 [00:01<00:00, 17277.03 examples/s]\n",
      "Map: 100%|██████████| 10087/10087 [00:00<00:00, 16739.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] really bad ux. old, outdated thinking. should be redesigned asap. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LF']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as a serialized file: output/serialized_encoded_review_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "#Saving the DataFrame as in serialized format to preserve the properties of the data structures(Tensor)\n",
    "\n",
    "import pickle\n",
    "\n",
    "#Define the file path where you want to save the serialized DataFrame\n",
    "file_path = 'output/serialized_encoded_review_dataset.pkl'\n",
    "\n",
    "# Step 3: Save the DataFrame using pickle\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(encoded_dataset, f)\n",
    "\n",
    "print(\"Dataset saved as a serialized file:\", file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
